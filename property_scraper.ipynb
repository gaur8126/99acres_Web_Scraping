{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ae290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ecfa2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PropertyScraper:\n",
    "    def __init__(self,url,timeout=5):\n",
    "        self.url = url \n",
    "        self.data = []\n",
    "        self.driver = self._initialize_driver()\n",
    "        self.wait = WebDriverWait(self.driver,timeout=timeout)\n",
    "\n",
    "    def _initialize_driver(self):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--disable-http2\")\n",
    "        chrome_options.add_argument(\"--incognito\")\n",
    "        chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "        chrome_options.add_argument(\"--ignore-certificate-errors\")\n",
    "        chrome_options.add_argument(\"--enable-features=NetworkServiceInProcess\")\n",
    "        chrome_options.add_argument(\"--disable-features=NetworkService\")\n",
    "        chrome_options.add_argument(\n",
    "            \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36\"\n",
    "        )\n",
    "\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        driver.maximize_window()\n",
    "\n",
    "        return driver\n",
    "    \n",
    "    def _wait_for_page_to_load(self):\n",
    "        title = self.driver.title\n",
    "        try:\n",
    "            self.wait.until(\n",
    "                lambda d:d.execute_script(\"return document.readyState\") == \"complete\"\n",
    "            )\n",
    "        except:\n",
    "            print(f\"The webpage \\\"{title}\\\"did not get fully loaded.\\n\")\n",
    "        else:\n",
    "            print(f\"The webpage \\\"{title}\\\" did get fully loaded.\\n\")\n",
    "        \n",
    "    \n",
    "    def access_website(self):\n",
    "        self.driver.get(self.url)\n",
    "        self._wait_for_page_to_load()\n",
    "\n",
    "    def search_properties(self,text):\n",
    "        # locating and entering text in search bar \n",
    "        try:\n",
    "            search_bar = self.wait.until(\n",
    "                EC.presence_of_element_located((By.XPATH, '//*[@id=\"keyword2\"]'))\n",
    "            )\n",
    "        except:\n",
    "            print(\"Timeout while locating Search Bar.\\n\")\n",
    "        else:\n",
    "            search_bar.send_keys(text)\n",
    "            time.sleep(random.uniform(2, 5))\n",
    "\n",
    "        # Selecting a valid option from the list\n",
    "        try:\n",
    "            valid_option = self.wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, '//*[@id=\"0\"]'))\n",
    "            )\n",
    "        except:\n",
    "            print(\"Timeout while locating valid search option.\\n\")\n",
    "        else:\n",
    "            valid_option.click()\n",
    "            time.sleep(random.uniform(2, 4))\n",
    "\n",
    "        # Click on the search button\n",
    "        try:\n",
    "            search_button = self.wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, '//*[@id=\"searchform_search_btn\"]'))\n",
    "            )\n",
    "        except:\n",
    "            print(\"Timeout while clicking the search button.\\n\")\n",
    "        else:\n",
    "            search_button.click()\n",
    "            self._wait_for_page_to_load()\n",
    "\n",
    "    def adjust_budget_slider(self,offset):\n",
    "        try:\n",
    "            slider =  self.wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH,'//*[@id=\"budgetLeftFilter_max_node\"]'))\n",
    "            )\n",
    "\n",
    "        except:\n",
    "            print(\"Timeout while clicking on budget slider circle.\\n\")\n",
    "        else:\n",
    "            actions = ActionChains(self.driver)\n",
    "            (\n",
    "                actions\n",
    "                .click_and_hold(slider)\n",
    "                .move_by_offset(offset,0)\n",
    "                .release()\n",
    "                .perform()\n",
    "            )\n",
    "            time.sleep(2)\n",
    "\n",
    "    def apply_filters(self):\n",
    "        # 1. verified \n",
    "        verified = self.wait.until(\n",
    "            EC.element_to_be_clickable((By.XPATH,'/html[1]/body[1]/div[1]/div[1]/div[1]/div[4]/div[3]/div[1]/div[3]/section[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[3]/span[2]'))\n",
    "        )\n",
    "        verified.click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        # 2. ready to move\n",
    "        ready_to_move = self.wait.until(\n",
    "            EC.element_to_be_clickable((By.XPATH,'/html[1]/body[1]/div[1]/div[1]/div[1]/div[4]/div[3]/div[1]/div[3]/section[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[5]/span[2]'))\n",
    "        )\n",
    "        ready_to_move.click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        # moving to the right side to unhide remaining filters \n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                filter_right_button = self.wait.until(\n",
    "                    EC.presence_of_element_located((By.XPATH,\"//i[@class='iconS_Common_24 icon_upArrow cc__rightArrow']\"))\n",
    "                )\n",
    "            except:\n",
    "                print(\"Timeout because we have uncovered all filers\")\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                filter_right_button.click()\n",
    "                time.sleep(1)\n",
    "\n",
    "        # 3. with Photos \n",
    "\n",
    "        try:\n",
    "            with_photos = self.wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH,\"//span[normalize-space()='With Photos']\"))\n",
    "            ) \n",
    "        except :\n",
    "            print(\"Timeout while click the option\")\n",
    "        else:\n",
    "            with_photos.click()\n",
    "            time.sleep(1)\n",
    "\n",
    "        # 4. with videos\n",
    "\n",
    "        try:\n",
    "            with_videos = self.wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH,\"//span[normalize-space()='With Videos']\"))\n",
    "            )\n",
    "        except:\n",
    "            print(\"Timeout while click the option\")\n",
    "        else:\n",
    "            with_videos.click()\n",
    "            time.sleep(1)\n",
    "\n",
    "    def _extract_data(self,row,by,value):\n",
    "        try:\n",
    "            return row.find_element(by,value).text\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    def scrap_webpage(self):\n",
    "        rows = self.driver.find_elements(By.CLASS_NAME,\"tupleNew__contentWrap\")\n",
    "        for row in rows:\n",
    "\n",
    "            property = {\n",
    "                'name':self._extract_data(row,By.CLASS_NAME,\"tupleNew__contentWrap\"),\n",
    "                'location': self._extract_data(row,By.CLASS_NAME,\"tupleNew__propType\"),\n",
    "                'price':self._extract_data(row,By.CLASS_NAME,\"tupleNew__priceValWrap\"),\n",
    "                \n",
    "            }\n",
    "            \n",
    "            ## property area and size(bhk) \n",
    "            try:\n",
    "                elements = row.find_elements(By.CLASS_NAME,\"tupleNew__area1Type\")\n",
    "            except:\n",
    "                property['area'],property['bhk'] = [np.nan,np.nan]\n",
    "            else:\n",
    "                property['area'],property['bhk'] = [ele.text for ele in elements]\n",
    "\n",
    "           \n",
    "            self.data.append(property)\n",
    "\n",
    "    def navigate_pages_and_scrape_data(self):\n",
    "        page_count = 0\n",
    "        while True:\n",
    "            page_count += 1\n",
    "            try:\n",
    "                time.sleep(3)\n",
    "                self.scrap_webpage()\n",
    "                next_page_button = self.driver.find_element(By.XPATH,\"//a[normalize-space()='Next Page >']\")\n",
    "            except:\n",
    "                print(f\"We have scraped {page_count} pages.\\n\")\n",
    "                break\n",
    "            else:\n",
    "                try:\n",
    "                    self.driver.execute_script(\"window.scrollBy(0, arguments[0].getBoundingClientRect().top - 100);\", next_page_button)\n",
    "                    time.sleep(2)\n",
    "\n",
    "                    self.wait.until(\n",
    "                        EC.element_to_be_clickable((By.XPATH, \"//a[normalize-space()='Next Page >']\"))\n",
    "                    ).click()\n",
    "                    # time.sleep(5)\n",
    "                except :\n",
    "                    print(\"Timeout while clicking on \\\"Next Page\\\".\\n\")\n",
    "\n",
    "    def clean_data_and_save_as_exel(self,file_name):\n",
    "        df_properties = (\n",
    "            pd\n",
    "            .DataFrame(self.data)\n",
    "            .drop_duplicates()\n",
    "            .apply(lambda col: col.str.strip().str.lower() if col.dtype == \"object\" else col)\n",
    "            .assign(\n",
    "                is_starred = lambda df_:df_.name.str.contains(\"\\n\").astype(int),\n",
    "                name = lambda df_ :(\n",
    "                    df_\n",
    "                    .name\n",
    "                    .str.replace(\"\\n[0-9.]+\",\"\",regex=True)\n",
    "                    .str.strip()\n",
    "                ),\n",
    "                location = lambda df_:(\n",
    "                    df_\n",
    "                    .location\n",
    "                    .str.replace(\"chennai\",\"\")\n",
    "                    .str.strip()\n",
    "                    .str.replace(\",$\",\"\",regex=True)\n",
    "                    .str.split(\"in\")\n",
    "                    .str[-1]\n",
    "                    .str.strip()\n",
    "                ),\n",
    "                price = lambda df_ :(\n",
    "                    df_\n",
    "                    .price\n",
    "                    .str.replace(\"₹\",\"\")\n",
    "                    .apply(lambda val: float(val.replace(\"lac\",\"\").strip()) if \"lac\" in val else float(val.replace(\"cr\",\"\").strip())*100)\n",
    "                ),\n",
    "                area = lambda df_ : (\n",
    "                    df_\n",
    "                    .area\n",
    "                    .str.replace(\"sqft\",\"\")\n",
    "                    .str.strip()\n",
    "                    .str.replace(\",\",\"\")\n",
    "                    .pipe(lambda ser:pd.to_numeric(ser))\n",
    "                ),\n",
    "                bhk = lambda df_ : (\n",
    "                    df_\n",
    "                    .bhk\n",
    "                    .str.replace(\"bhk\",\"\")\n",
    "                    .str.strip()\n",
    "                    .pipe(lambda ser:pd.to_numeric(ser))\n",
    "                    \n",
    "                )\n",
    "            )\n",
    "            .rename(columns={\n",
    "                \"price\":\"price_lakhs\",\n",
    "                \"area\":\"area_sqft\"\n",
    "            })\n",
    "            .reset_index(drop=True)\n",
    "            \n",
    "        )\n",
    "        df_properties.to_excel(f\"{file_name}.xlsx\",index=False)\n",
    "                \n",
    "    \n",
    "    def run(self,text='Chennai',offset = -100,file_name=\"properties\"):\n",
    "        try:\n",
    "            self.access_website()\n",
    "            self.search_properties(text)\n",
    "            self.adjust_budget_slider(offset=-73)\n",
    "            self.apply_filters()\n",
    "            self.navigate_pages_and_scrape_data()\n",
    "            self.clean_data_and_save_as_exel(file_name=file_name)\n",
    "        finally:\n",
    "            \n",
    "            self.driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0496a84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The webpage \"India Real Estate Property Site - Buy Sell Rent Properties Portal - 99acres.com\" did get fully loaded.\n",
      "\n",
      "The webpage \"Property in Chennai - Real Estate in Chennai\" did get fully loaded.\n",
      "\n",
      "Timeout because we have uncovered all filers\n",
      "Timeout while clicking on \"Next Page\".\n",
      "\n",
      "Timeout while clicking on \"Next Page\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    scraper = PropertyScraper(\"https://www.99acres.com/\")\n",
    "    scraper.run(\n",
    "        text=\"Chennai\"\n",
    "        ,offset=-73,\n",
    "        file_name=\"chennai-properties-2\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dba503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscrap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
